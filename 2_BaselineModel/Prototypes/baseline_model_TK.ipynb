{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "## Table of Contents\n",
    "1. [Infrastructure](#infrastructure)\n",
    "2. [Model Choice](#model-choice)\n",
    "3. [Feature Selection](#feature-selection)\n",
    "4. [Implementation](#implementation)\n",
    "5. [Evaluation](#evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q datasets huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from huggingface_hub import login, list_repo_files, hf_hub_download\n",
    "\n",
    "# Import your chosen baseline model\n",
    "# Example: from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "token = \"\" # Your Hugging Face token here\n",
    "REPO_ID = \"mttfst/Paulette_Cloud_Tracks\"\n",
    "\n",
    "login(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import login\n",
    "# from google.colab import userdata\n",
    "\n",
    "# token = userdata.get('hf')\n",
    "# login(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CSV tracks: 9227\n",
      "Train tracks: 6458\n",
      "Val tracks:   1384\n",
      "Test tracks:  1385\n"
     ]
    }
   ],
   "source": [
    "# 1) Alle Files im Repo holen\n",
    "files = list_repo_files(REPO_ID, repo_type=\"dataset\")\n",
    "\n",
    "# 2) Nur die Track-CSV-Dateien f√ºr exp_1.1 ausw√§hlen\n",
    "csv_files = [f for f in files if f.startswith(\"exp_1.1/\") and f.endswith(\".csv\")]\n",
    "print(\"Total CSV tracks:\", len(csv_files))\n",
    "\n",
    "# 3) Reproduzierbar mischen\n",
    "random.seed(42)        # fixer Seed, damit der Split immer gleich ist\n",
    "csv_files_shuffled = csv_files.copy()\n",
    "random.shuffle(csv_files_shuffled)\n",
    "\n",
    "# 4) 70/15/15 Split auf Track-Ebene\n",
    "n = len(csv_files_shuffled)\n",
    "n_train = int(0.7 * n)\n",
    "n_val   = int(0.15 * n)\n",
    "# Rest geht in Test\n",
    "n_test  = n - n_train - n_val\n",
    "\n",
    "train_files = csv_files_shuffled[:n_train]\n",
    "val_files   = csv_files_shuffled[n_train:n_train + n_val]\n",
    "test_files  = csv_files_shuffled[n_train + n_val:]\n",
    "\n",
    "print(f\"Train tracks: {len(train_files)}\")\n",
    "print(f\"Val tracks:   {len(val_files)}\")\n",
    "print(f\"Test tracks:  {len(test_files)}\")\n",
    "\n",
    "# Optional: in einem Dict sammeln, damit es √ºbersichtlich bleibt\n",
    "split_files = {\n",
    "    \"train\": train_files,\n",
    "    \"val\": val_files,\n",
    "    \"test\": test_files,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_stats_features_placeholder(\n",
    "    df: pd.DataFrame,\n",
    "    timestep_seconds: float = 30.0,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Placeholder for Task A.2 feature engineering.\n",
    "    Here we will later add:\n",
    "    - running means / max over past N timesteps\n",
    "    - growth rates (e.g. d(area)/dt)\n",
    "    - integrated column values, etc.\n",
    "\n",
    "    For now, this function just returns df unchanged.\n",
    "    \"\"\"\n",
    "    # Example of something we *could* already add (optional, kannst du auch rauslassen):\n",
    "    # df[\"track_length_s\"] = df[\"age_s\"].iloc[-1] + timestep_seconds\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_track(\n",
    "    df: pd.DataFrame,\n",
    "    timestep_seconds: float = 30.0,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess a single cloud track:\n",
    "    - ensure correct ordering\n",
    "    - create local frame index (0..T-1)\n",
    "    - compute remaining_lifetime_s per timestep\n",
    "    - optionally drop useless columns (e.g. global time stamp)\n",
    "    - hook for later stats features (Task A.2)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Safety: ensure sorted by frame (global frame currently)\n",
    "    if \"frame\" in df.columns:\n",
    "        df = df.sort_values(\"frame\").reset_index(drop=True)\n",
    "    \n",
    "    T = len(df)\n",
    "    \n",
    "    # 1) Preserve original global frame (for debugging if needed)\n",
    "    if \"frame\" in df.columns:\n",
    "        df[\"frame_global\"] = df[\"frame\"]\n",
    "    \n",
    "    # 2) Create local frame index: 0, 1, ..., T-1\n",
    "    df[\"frame\"] = np.arange(T, dtype=int)\n",
    "    \n",
    "    # 3) Age of the cloud at each timestep (could be useful feature)\n",
    "    df[\"age_s\"] = df[\"frame\"] * timestep_seconds\n",
    "    \n",
    "    # 4) Remaining lifetime from each timestep\n",
    "    #    Last timestep (frame = T-1) ‚Üí 0 seconds remaining\n",
    "    df[\"remaining_lifetime_s\"] = (T - 1 - df[\"frame\"]) * timestep_seconds\n",
    "    \n",
    "    # 5) Drop irrelevant columns (start minimal; wirf 'time' raus)\n",
    "    cols_to_drop = []\n",
    "    if \"time\" in df.columns:\n",
    "        cols_to_drop.append(\"time\")\n",
    "    \n",
    "    # falls du noch andere Spalten immer loswerden willst:\n",
    "    for c in [\"feature\", \"feature_orig\", \"cell\", \"latitude\",  \"longitude\"]:\n",
    "        if c in df.columns:\n",
    "            cols_to_drop.append(c)\n",
    "    \n",
    "    if cols_to_drop:\n",
    "        df = df.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # 6) Placeholder: add stats-based features for Task A.2 (snapshot + stats)\n",
    "    df = add_stats_features_placeholder(df, timestep_seconds=timestep_seconds)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example track file: exp_1.1/cell_08568.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track shape: (4, 413)\n",
      "Columns: Index(['frame', 'qv_L00', 'qv_L01', 'qv_L02', 'qv_L03', 'qv_L04', 'qv_L05',\n",
      "       'qv_L06', 'qv_L07', 'qv_L08'],\n",
      "      dtype='object')\n",
      "   frame    qv_L00    qv_L01    qv_L02    qv_L03    qv_L04    qv_L05  \\\n",
      "0      0  0.000002  0.000002  0.000002  0.000002  0.000002  0.000002   \n",
      "1      1  0.000002  0.000002  0.000002  0.000002  0.000002  0.000002   \n",
      "2      2  0.000002  0.000002  0.000002  0.000002  0.000002  0.000002   \n",
      "3      3  0.000002  0.000002  0.000002  0.000002  0.000002  0.000002   \n",
      "\n",
      "     qv_L06    qv_L07    qv_L08  ...    lwp_L00   iwp_L00  cin_ml_L00  \\\n",
      "0  0.000003  0.000007  0.000004  ...  12.609904  0.052129         NaN   \n",
      "1  0.000003  0.000007  0.000004  ...  12.313472  0.044247         NaN   \n",
      "2  0.000003  0.000007  0.000004  ...  11.949812  0.036808    0.865642   \n",
      "3  0.000003  0.000007  0.000004  ...  11.531737  0.029802         NaN   \n",
      "\n",
      "    tqc_L00  rain_gsp_rate_L00   tqi_L00      area_m2  frame_global  age_s  \\\n",
      "0  2.852148           0.009231  0.004912  305760000.0          5288    0.0   \n",
      "1  2.866157           0.008772  0.005105  305760000.0          5289   30.0   \n",
      "2  2.874345           0.008208  0.005303  305760000.0          5290   60.0   \n",
      "3  2.881648           0.007617  0.005503  305760000.0          5291   90.0   \n",
      "\n",
      "   remaining_lifetime_s  \n",
      "0                  90.0  \n",
      "1                  60.0  \n",
      "2                  30.0  \n",
      "3                   0.0  \n",
      "\n",
      "[4 rows x 413 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_track(csv_path_in_repo: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    L√§dt einen einzelnen Track (eine CSV-Datei) aus dem HF-Dataset\n",
    "    und gibt ein nach 'frame' sortiertes pandas DataFrame zur√ºck.\n",
    "    \n",
    "    csv_path_in_repo: z.B. \"exp_1.1/track_000001.csv\"\n",
    "    \"\"\"\n",
    "    # 1) Datei von HF runterladen (wird lokal gecached)\n",
    "    local_path = hf_hub_download(\n",
    "        repo_id=REPO_ID,\n",
    "        repo_type=\"dataset\",\n",
    "        filename=csv_path_in_repo,\n",
    "    )\n",
    "    \n",
    "    # 2) CSV in DataFrame laden\n",
    "    df = pd.read_csv(local_path)\n",
    "    \n",
    "    # 3) Nach 'frame' sortieren (oder 'time', wenn du lieber Zeitstempel nutzt)\n",
    "    if \"frame\" in df.columns:\n",
    "        df = df.sort_values(\"frame\").reset_index(drop=True)\n",
    "    elif \"time\" in df.columns:\n",
    "        df = df.sort_values(\"time\").reset_index(drop=True)\n",
    "    else:\n",
    "        raise ValueError(\"Neither 'frame' nor 'time' column found in track CSV.\")\n",
    "    \n",
    "    df = preprocess_track(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Test: ersten Train-Track laden\n",
    "example_track_file = train_files[0]\n",
    "print(\"Example track file:\", example_track_file)\n",
    "\n",
    "track_df = load_track(example_track_file)\n",
    "print(\"Track shape:\", track_df.shape)\n",
    "print(\"Columns:\", track_df.columns[:10])  # nur die ersten paar Spalten\n",
    "print(track_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_track_long_enough(df, cutoff_steps: int = 5) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if the track has enough timesteps to be used for Task A\n",
    "    (remaining lifetime prediction) with the given cutoff at the end.\n",
    "    \"\"\"\n",
    "    T = len(df)\n",
    "    # we need at least one valid t in [0, T-1-cutoff_steps]\n",
    "    return T > cutoff_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example track file: exp_1.1/cell_08568.csv\n",
      "Track shape: (4, 413)\n",
      "   frame  frame_global  age_s  remaining_lifetime_s\n",
      "0      0          5288    0.0                  90.0\n",
      "1      1          5289   30.0                  60.0\n",
      "2      2          5290   60.0                  30.0\n",
      "3      3          5291   90.0                   0.0\n",
      "   frame  age_s  remaining_lifetime_s\n",
      "0      0    0.0                  90.0\n",
      "1      1   30.0                  60.0\n",
      "2      2   60.0                  30.0\n",
      "3      3   90.0                   0.0\n"
     ]
    }
   ],
   "source": [
    "example_track_file = train_files[0]\n",
    "print(\"Example track file:\", example_track_file)\n",
    "\n",
    "track_df = load_track(example_track_file)\n",
    "\n",
    "print(\"Track shape:\", track_df.shape)\n",
    "print(track_df[[\"frame\", \"frame_global\", \"age_s\", \"remaining_lifetime_s\"]].head())\n",
    "print(track_df[[\"frame\", \"age_s\", \"remaining_lifetime_s\"]].tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Choice\n",
    "\n",
    "[Explain why you've chosen a particular model as the baseline. This could be a simple statistical model or a basic machine learning model. Justify your choice.]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "[Indicate which features from the dataset you will be using for the baseline model, and justify your selection.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALAR_BASE_FEATURES = [\n",
    "    \"cape_ml_L00\",\n",
    "    \"cin_ml_L00\",\n",
    "    \"lwp_L00\",\n",
    "    \"iwp_L00\",\n",
    "    \"tqc_L00\",\n",
    "    \"tqi_L00\",\n",
    "    \"rain_gsp_rate_L00\",\n",
    "    \"area_m2\",\n",
    "    \"age_s\",\n",
    "]\n",
    "\n",
    "def get_scalar_feature_columns(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Returns the list of scalar feature columns to use\n",
    "    for the snapshot baseline (Task A.1).\n",
    "    \n",
    "    Only uses a predefined set of scalar features.\n",
    "    Profile variables qv_Lxx, w_Lxx, qc_Lxx, etc. are ignored.\n",
    "    \"\"\"\n",
    "    feature_cols = [c for c in SCALAR_BASE_FEATURES if c in df.columns]\n",
    "    return feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_snapshot_from_track(\n",
    "    df: pd.DataFrame,\n",
    "    num_samples_per_track: int = 3,\n",
    "    cutoff_steps: int = 5,\n",
    "    rng: np.random.Generator | None = None,\n",
    "):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    \n",
    "    T = len(df)\n",
    "    \n",
    "    if not is_track_long_enough(df, cutoff_steps=cutoff_steps):\n",
    "        return None, None, None, None\n",
    "    \n",
    "    max_valid_t = T - 1 - cutoff_steps\n",
    "    valid_indices = np.arange(0, max_valid_t + 1)\n",
    "    \n",
    "    if len(valid_indices) == 0:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    n_samples = min(num_samples_per_track, len(valid_indices))\n",
    "    \n",
    "    if n_samples == len(valid_indices):\n",
    "        chosen_t = valid_indices\n",
    "    else:\n",
    "        chosen_t = rng.choice(valid_indices, size=n_samples, replace=False)\n",
    "    \n",
    "    chosen_t = np.sort(chosen_t)\n",
    "    \n",
    "    # üëâ neu: nur skalare Features\n",
    "    feature_cols = get_scalar_feature_columns(df)\n",
    "    \n",
    "    if len(feature_cols) == 0:\n",
    "        raise ValueError(\"No scalar feature columns found in track DataFrame.\")\n",
    "    \n",
    "    X = df.loc[chosen_t, feature_cols].to_numpy(dtype=np.float32)\n",
    "    y = df.loc[chosen_t, \"remaining_lifetime_s\"].to_numpy(dtype=np.float32)\n",
    "    \n",
    "    return X, y, chosen_t, feature_cols\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen timesteps: [ 2  9 10]\n",
      "Feature columns: ['cape_ml_L00', 'cin_ml_L00', 'lwp_L00', 'iwp_L00', 'tqc_L00', 'tqi_L00', 'rain_gsp_rate_L00', 'area_m2', 'age_s']\n",
      "X shape: (3, 9)\n",
      "y: [570. 360. 330.]\n",
      "First sample (as dict):\n",
      "{'cape_ml_L00': np.float32(nan), 'cin_ml_L00': np.float32(nan), 'lwp_L00': np.float32(4.2851415), 'iwp_L00': np.float32(0.6015448), 'tqc_L00': np.float32(2.0657444), 'tqi_L00': np.float32(0.2333252), 'rain_gsp_rate_L00': np.float32(0.0035198503), 'area_m2': np.float32(31360000.0), 'age_s': np.float32(60.0)}\n"
     ]
    }
   ],
   "source": [
    "example_track_file = train_files[2]\n",
    "track_df = load_track(example_track_file)\n",
    "\n",
    "X, y, t_idx, feat_cols = sample_snapshot_from_track(\n",
    "    track_df,\n",
    "    num_samples_per_track=3,\n",
    "    cutoff_steps=5,\n",
    ")\n",
    "\n",
    "print(\"Chosen timesteps:\", t_idx)\n",
    "print(\"Feature columns:\", feat_cols)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y:\", y)\n",
    "print(\"First sample (as dict):\")\n",
    "print(dict(zip(feat_cols, X[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_snapshot_dataset(\n",
    "    file_list,\n",
    "    num_samples_per_track: int = 3,\n",
    "    cutoff_steps: int = 5,\n",
    "    max_tracks: int | None = None,\n",
    "    rng_seed: int = 0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a snapshot-based dataset for Task A (remaining lifetime) from many tracks.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_list : list of str\n",
    "        List of CSV paths inside the HF repo (e.g. split_files[\"train\"]).\n",
    "    num_samples_per_track : int\n",
    "        How many timesteps t to sample per track (max).\n",
    "    cutoff_steps : int\n",
    "        How many last timesteps to exclude from being chosen as inputs.\n",
    "    max_tracks : int or None\n",
    "        If not None, limit the number of tracks to this value (for quick tests).\n",
    "    rng_seed : int\n",
    "        Seed for the random generator (for reproducibility).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X : np.ndarray, shape (N_samples, N_features)\n",
    "    y : np.ndarray, shape (N_samples,)\n",
    "    feature_cols : list of str\n",
    "        Names of the feature columns in the same order as in X.\n",
    "    stats : dict\n",
    "        Some info: how many tracks used, how many skipped, etc.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(rng_seed)\n",
    "    \n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    n_tracks_total = 0\n",
    "    n_tracks_used = 0\n",
    "    n_tracks_too_short = 0\n",
    "    n_tracks_no_samples = 0\n",
    "    \n",
    "    feature_cols_ref = None\n",
    "    \n",
    "    for i, csv_path in enumerate(file_list):\n",
    "        n_tracks_total += 1\n",
    "        \n",
    "        if (max_tracks is not None) and (i >= max_tracks):\n",
    "            break\n",
    "        \n",
    "        # Track laden + preprocess\n",
    "        df = load_track(csv_path)\n",
    "        \n",
    "        # L√§nge pr√ºfen\n",
    "        if not is_track_long_enough(df, cutoff_steps=cutoff_steps):\n",
    "            n_tracks_too_short += 1\n",
    "            continue\n",
    "        \n",
    "        # Snapshot-Samples aus diesem Track ziehen\n",
    "        X, y, t_idx, feature_cols = sample_snapshot_from_track(\n",
    "            df,\n",
    "            num_samples_per_track=num_samples_per_track,\n",
    "            cutoff_steps=cutoff_steps,\n",
    "            rng=rng,\n",
    "        )\n",
    "        \n",
    "        if X is None or len(X) == 0:\n",
    "            n_tracks_no_samples += 1\n",
    "            continue\n",
    "        \n",
    "        # Feature-Spaltenkonsistenz checken\n",
    "        if feature_cols_ref is None:\n",
    "            feature_cols_ref = feature_cols\n",
    "        else:\n",
    "            if feature_cols != feature_cols_ref:\n",
    "                raise ValueError(\n",
    "                    f\"Inconsistent feature columns in track {csv_path}.\"\n",
    "                )\n",
    "        \n",
    "        X_list.append(X)\n",
    "        y_list.append(y)\n",
    "        n_tracks_used += 1\n",
    "    \n",
    "    if len(X_list) == 0:\n",
    "        raise RuntimeError(\"No samples collected; check cutoff_steps or file_list.\")\n",
    "    \n",
    "    X_all = np.concatenate(X_list, axis=0)\n",
    "    y_all = np.concatenate(y_list, axis=0)\n",
    "    \n",
    "    stats = {\n",
    "        \"n_tracks_total\": n_tracks_total,\n",
    "        \"n_tracks_used\": n_tracks_used,\n",
    "        \"n_tracks_too_short\": n_tracks_too_short,\n",
    "        \"n_tracks_no_samples\": n_tracks_no_samples,\n",
    "        \"n_samples\": len(y_all),\n",
    "        \"n_features\": X_all.shape[1],\n",
    "    }\n",
    "    \n",
    "    return X_all, y_all, feature_cols_ref, stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train stats: {'n_tracks_total': 1001, 'n_tracks_used': 737, 'n_tracks_too_short': 263, 'n_tracks_no_samples': 0, 'n_samples': 2101, 'n_features': 9}\n",
      "X_train shape: (2101, 9)\n",
      "y_train shape: (2101,)\n",
      "Feature columns: ['cape_ml_L00', 'cin_ml_L00', 'lwp_L00', 'iwp_L00', 'tqc_L00', 'tqi_L00', 'rain_gsp_rate_L00', 'area_m2', 'age_s']\n",
      "First sample: {'cape_ml_L00': np.float32(nan), 'cin_ml_L00': np.float32(nan), 'lwp_L00': np.float32(4.123248), 'iwp_L00': np.float32(0.21214005), 'tqc_L00': np.float32(2.1722622), 'tqi_L00': np.float32(0.05314788), 'rain_gsp_rate_L00': np.float32(7.3694406e-05), 'area_m2': np.float32(31360000.0), 'age_s': np.float32(0.0)}\n",
      "First label (remaining_lifetime_s): 180.0\n"
     ]
    }
   ],
   "source": [
    "# Beispiel: nur 100 Tracks f√ºr einen ersten Test\n",
    "X_train, y_train, feature_cols, train_stats = build_snapshot_dataset(\n",
    "    train_files,\n",
    "    num_samples_per_track=3,\n",
    "    cutoff_steps=5,\n",
    "    max_tracks=1000,    # zum Testen; sp√§ter None setzen f√ºr alle\n",
    "    rng_seed=42,\n",
    ")\n",
    "\n",
    "print(\"Train stats:\", train_stats)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"Feature columns:\", feature_cols)\n",
    "print(\"First sample:\", dict(zip(feature_cols, X_train[0])))\n",
    "print(\"First label (remaining_lifetime_s):\", y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val stats: {'n_tracks_total': 501, 'n_tracks_used': 370, 'n_tracks_too_short': 130, 'n_tracks_no_samples': 0, 'n_samples': 1050, 'n_features': 9}\n",
      "Test stats: {'n_tracks_total': 501, 'n_tracks_used': 375, 'n_tracks_too_short': 125, 'n_tracks_no_samples': 0, 'n_samples': 1078, 'n_features': 9}\n"
     ]
    }
   ],
   "source": [
    "X_val, y_val, _, val_stats = build_snapshot_dataset(\n",
    "    val_files,\n",
    "    num_samples_per_track=3,\n",
    "    cutoff_steps=5,\n",
    "    max_tracks=500,\n",
    "    rng_seed=123,\n",
    ")\n",
    "\n",
    "X_test, y_test, _, test_stats = build_snapshot_dataset(\n",
    "    test_files,\n",
    "    num_samples_per_track=3,\n",
    "    cutoff_steps=5,\n",
    "    max_tracks=500,\n",
    "    rng_seed=456,\n",
    ")\n",
    "\n",
    "print(\"Val stats:\", val_stats)\n",
    "print(\"Test stats:\", test_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "[Implement your baseline model here.]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting RandomForestRegressor on X_train with shape: (2101, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=200, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(n_estimators=200, n_jobs=-1, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(n_estimators=200, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple baseline model for Task A (remaining lifetime)\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=200,      # number of trees\n",
    "    max_depth=None,       # let trees grow fully (kannst sp√§ter begrenzen)\n",
    "    n_jobs=-1,            # alle CPUs nutzen\n",
    "    random_state=42,      # reproducible\n",
    ")\n",
    "\n",
    "print(\"Fitting RandomForestRegressor on X_train with shape:\", X_train.shape)\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "[Clearly state what metrics you will use to evaluate the model's performance. These metrics will serve as a starting point for evaluating more complex models later on.]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluation Task A (Snapshot Baseline, scalar features only) ===\n",
      "Train - MAE:  273.12 s\n",
      "Train - RMSE: 495.82 s\n",
      "Val - MAE:  818.44 s\n",
      "Val - RMSE: 1451.29 s\n",
      "Test - MAE:  732.65 s\n",
      "Test - RMSE: 1227.20 s\n"
     ]
    }
   ],
   "source": [
    "def evaluate_regression(model, X, y, name: str = \"set\"):\n",
    "    y_pred = model.predict(X)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(f\"{name} - MAE:  {mae:.2f} s\")\n",
    "    print(f\"{name} - RMSE: {rmse:.2f} s\")\n",
    "    return {\"mae\": mae, \"rmse\": rmse, \"y_pred\": y_pred}\n",
    "\n",
    "print(\"\\n=== Evaluation Task A (Snapshot Baseline, scalar features only) ===\")\n",
    "train_metrics = evaluate_regression(rf, X_train, y_train, name=\"Train\")\n",
    "val_metrics   = evaluate_regression(rf, X_val,   y_val,   name=\"Val\")\n",
    "test_metrics  = evaluate_regression(rf, X_test,  y_test,  name=\"Test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 15 features by importance:\n",
      "             feature  importance\n",
      "2            lwp_L00    0.226060\n",
      "8              age_s    0.216965\n",
      "4            tqc_L00    0.123196\n",
      "3            iwp_L00    0.114900\n",
      "6  rain_gsp_rate_L00    0.107071\n",
      "7            area_m2    0.100798\n",
      "5            tqi_L00    0.084940\n",
      "0        cape_ml_L00    0.016229\n",
      "1         cin_ml_L00    0.009840\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "feature_importances = rf.feature_importances_\n",
    "fi_df = pd.DataFrame({\n",
    "    \"feature\": feature_cols,\n",
    "    \"importance\": feature_importances,\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 features by importance:\")\n",
    "print(fi_df.head(15))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
